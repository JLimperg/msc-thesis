\documentclass{scrartcl}
\usepackage[british]{babel}
\usepackage{fontspec}
\usepackage{unicode-math}
\usepackage{csquotes}
\usepackage{hyperref}

\setmainfont{TeX Gyre Termes}
\setmathfont{TeX Gyre Termes Math}
\setmonofont[Scale=0.8]{DejaVu Sans Mono}

\setlength{\parskip}{10pt} 


\newcommand*{\Nat}{\ensuremath{\mathrm{\mathbb{N}}}}
\newcommand*{\Sets}{\ensuremath{\mathrm{Sets}}}
\newcommand*{\Ords}{\ensuremath{\mathrm{Ords}}}
\newcommand*{\op}[1]{\ensuremath{#1^\mathrm{op}}}
\newcommand*{\cod}[1]{\texttt{#1}}


\begin{document}

\begin{titlepage}

\centering
  
  
{\scshape\LARGE Master thesis planning report\\}
  
\vspace{0.5cm}
  
{\huge\bfseries Modeling Agda's Sized Types in Agda \\}
  
\vspace{2cm}
  
{\Large Jannis Limperg <limperg@student.chalmers.se>\\}
  
\vspace{1.0cm}
  
{\large Supervisor: Andreas Abel\\}
  
\vfill
  
{\large \today\\} 

\end{titlepage}

\section{Introduction}

One of the primary benefits of dependently typed functional programming
languages like Coq \cite{coq} and Agda \cite{norellphd} is that their types
correspond to propositions and their programs to proofs \cite{curry1958,
  debruijn1970, howard1980}. This correspondence allows programmers to verify
properties of their programs -- in the extreme: full functional correctness --
without having to reach for special-purpose, complex, sometimes buggy or limited
external tools like model checkers or deductive verification systems.
(We elaborate on this, and on many of the following concepts, in Sec.
\ref{sec:background}.)

Unfortunately, this \enquote*{dual use} of the system as a language and logic
imposes some constraints on the system's design. Chief among these is
termination checking: To prevent users from defining \texttt{bad := bad} and
calling it a proof of any proposition whatsoever, we must ensure that all
computations terminate in finite time.

Traditionally, this constraint has been implemented by syntactic termination
checkers \cite{gimenez1995}. To accommodate definitions with a nontrivial
recursion structure, these checkers have become quite sophisticated, supporting
things like mutual recursion and lexicographic termination measures
\cite{abel2002}. However, with sophistication come bugs, which may jeopardise
the system's logical consistency (and this has happened to both Coq and Agda
\cite{coqbug2013, agdabug2013}). And despite all efforts to make termination
checkers more liberal, some innocuous-looking operations, like the mapping
function for Rose trees, must still be written in a convoluted way to please the
checker. 

For these reasons, alternative approaches under the heading of \emph{sized
  types} have attracted much interest. These annotate inductive data types with
sizes, which constitute an upper bound on the height of values (when we view
values as trees whose nodes are constructors). Thus, the successor constructor
of sized natural numbers has type $\Nat^i → \Nat^{i ↑}$ for any size $i$: It
takes a natural number with at most $i$ constructors and produces a natural
number with at most $i + 1$ constructors. With this setup, termination checking
becomes simple: If a recursive function takes an argument of type $\Nat^i$, and
any recursive calls take arguments of type $\Nat^j$ with sizes $j < i$, then the
recursion must reach size 0 eventually, and thus terminate.

Sized types thus largely reduce termination checking to type checking. They also
naturally extend to coinductive types like infinite streams or trees.
$\mathrm{Stream}ⁱ$, for example, is the type of streams which allow observation
of the first $i$ elements. Obviously, if these streams are to be infinite,
functions which generate them cannot terminate, but they can -- and must, if we
want to preserve logical consistency -- be \emph{productive}. This means that
any observation of the stream takes only finite time, which leads to a reduction
of productivity checking to termination checking: A corecursive definition is
productive if any observation of it terminates. Agda's sized types
\cite{abel2016}, which we propose to investigate in the thesis, takes advantage
of this reduction to get rid of termination and productivity checking in one
fell swoop.

We aim to justify Agda's design of sized types by constructing a
category-theoretical model of a simply typed lambda calculus extended with sized
types that mimic Agda's. The construction will be formalised in
Agda-without-sized-types, so we will use Agda as the metalanguage, but not its
sized types, to avoid circular reasoning. Constructing this model is interesting
for several reasons:
\begin{itemize}
\item Agda's current implementation of sized types is known to be inconsistent
  \cite{agdabug-sized2015, agdabug-sized2017}. While fixing it is likely out of
  scope for this thesis, our model construction may inform the design of a
  solution. In particular, current Agda has a size $∞$ which denotes
  \enquote*{fully defined} data types and is considered smaller than itself: $∞
  < ∞$. This rule, together with other Agda features, makes it possible to sneak
  a nonterminating program past the termination checker, leading to a proof of
  the false proposition. It is currently unclear how to fix this issue without
  restricting the power of sized types too much. This is where our project comes
  in: Any issues we encounter while constructing the model may yield insights
  into what exactly causes the current inconsistency. Additionally, the
  construction itself may suggest possible fixes. For example, Agda's
  \texttt{Size} type currently lives in the smallest universe, \texttt{Set₀}. If
  it turns out (as we suspect) that our model of sizes does not fit into
  \texttt{Set₀}, this would support the hypothesis that Agda's sizes should be
  stratified across multiple universes.
\item Beyond fixing the mentioned problems with the current design of sized
  types, our model may suggest further improvements: If we find interesting
  operations in the model, then we could allow users to perform corresponding
  operations on sized types.
\item Category-theoretical models provide an elegant way to prove properties
  about type theories. If we find out how sized types fit into a categorical
  framework, this may ease the development of categorical models for other type
  theories involving sizes.
\item Our model, or at least significant parts of it, will be formally verified
  since we work in Agda itself.
\end{itemize}


\section{Background}
\label{sec:background}

\subsection{Agda and Dependent Types}

Agda is a purely functional programming language. Its syntax is similar to
Haskell's, but it merges the grammars for terms and types, so a type may contain
arbitrary terms. (However, not every term makes sense as a type, so the type
system ensures that only certain terms are used as types.) This enables its
headline feature, dependent types, which come in two forms: dependent functions
and indexed (co)inductive types.

A dependent function type is written \cod{(x~:~A)~→~B}, where \cod{x} is a
variable and \cod{A, B} are types. Crucially, \cod{x} may appear free in
\cod{B}. This means that a dependent function can return values of different
types, depending on the argument it is applied to. For example, the function
\begin{verbatim}
  toy : (x : Bool) → (if x then Bool else ℕ)
  toy true  = false
  toy false = 0
\end{verbatim}
returns a boolean when applied to \cod{true} and a natural number otherwise.
Note how an \cod{if} expression, a construct usually resigned to the term
level, appears in the type.

The definition of \cod{toy} proceeds by pattern matching on the function's
argument -- this works like in Haskell and similar languages, but a pattern
match may refine the types of other patterns and the type of the equation's
right-hand side. For example, when we match \cod{true} in the first equation,
Agda simplifies the type of the right-hand side to \cod{Bool} by substituting
\cod{x~≔~true} in the return type and reducing the \cod{if} expression.

\cod{toy} is not a very interesting function, but dependent types can be put to
better use. One classic example is the family of vectors, which are lists whose
length is reflected in their type. The type of vectors of length \cod{n} is
called \cod{Vec~A~n}, where \cod{A} is a type and \cod{n} is a (Peano)
natural number. Given this type, we can more precisely specify the behaviour of,
for example, the \cod{head} function:
\begin{verbatim}
  head : ∀ {A n} → Vec A (suc n) → A
\end{verbatim}
\cod{head} only makes sense for lists of length at least one, so we demand that
the length of the input list is the successor of some natural number \cod{n} --
i.e., is at least one. \cod{∀~A~→~T} is a shortcut for \cod{(A~:~\_)~→~T}
whenever Agda can infer the type of \cod{A}. The function type \cod{A~→~B} is a
shortcut for \cod{(x~:~A)~→~B} where \cod{x} does not appear free in \cod{B} (so
a dependent function without any dependency is just a regular old function).
Putting curly braces around the type of a function's argument, as for \cod{A}
and \cod{n}, lets us omit these arguments when applying \cod{head}, so we can
write \cod{head~xs} instead of \cod{head~A~n~xs} and Agda will try to infer the
first two arguments.

The second piece of the dependent types puzzle is indexed (co)inductive types.
These look and function much like Haskell's Generalised Algebraic Datatypes. Our
\cod{Vec} type is a typical example:
\begin{verbatim}
  data Vec (A : Set) : ℕ → Set where
    nil :                        Vec A 0
    cons : ∀ {n} → A → Vec A n → Vec A (suc n)
\end{verbatim}
\cod{Vec} is declared as an inductive type with one parameter, \cod{A}, and one
index of type \cod{ℕ}. This gives \cod{Vec} the type \cod{Set → ℕ → Set}.
(\cod{Set} is Agda's name for the type of (small) types.) It has two
constructors \cod{nil} and \cod{cons}, corresponding to the usual list
constructors. The magic is in the constructor types: they end in \cod{Vec A n},
where the \emph{parameter} \cod{A} must be the same in all constructors, but the
\emph{index} \cod{n} can vary between different constructors. Thus, we can
express that the empty vector, \cod{nil}, has length zero, and the length of
\cod{cons x xs} is one greater than the length of \cod{xs}.


\subsection{Curry-Howard-de Bruijn Correspondence}

The Curry-Howard-de Bruijn correspondence (Curry-Howard for short) is the
powerful observation that certain types in a dependently typed language can be
viewed as logical propositions, and programs of these types can be viewed as
proofs.

For example, the inhabitants of the product type \cod{A × B} are pairs, each
consisting of an element of \cod{A} and an element of \cod{B}. But this is
exactly what a proof of the proposition $A ∧ B$ (in intuitionistic propositional
logic) looks like: It is a pair of proofs, one of \cod{A} and one of \cod{B}.
Similarly, a proof of the implication $A → B$ may be understood as a function
which takes a proof of $A$ and returns a proof of $B$. The false proposition
$⊥$ corresponds to the empty type (which has no inhabitants, and thus no
proofs), and a similar computational interpretation can be given for the
disjunction $A ∨ B$.

The dependent function type corresponds to universal quantification, lifting the
correspondence from the relatively mundane world of propositional logic to a
much more interesting (and useful) higher-order logic. A proof of the
proposition $∀x, P$ may be understood as a function that returns, for each $a$
(of some type $A$), a proof of $P[x ≔ a]$, i.e. a proof of the proposition $P$
with all free occurrences of $x$ replaced by the argument $a$. But this is
exactly a dependent function \cod{(x~:~A)~→~P}.

Meanwhile, inductive types can be used to define pairs, the \cod{Either} type
(which corresponds to disjunction) and the empty type, just like in Haskell.
They can also be used to define dependent pairs, usually written \cod{Σ A P},
which are pairs of elements \cod{a : A} and \cod{p : P[x ≔ a]}. The second
component can be read as a proof that the proposition $P$ holds for $a$, so if
\cod{Σ A P} is inhabited, we know that there exists an $a$ such that $P(a)$ --
dependent pairs thus represent existential quantification.

Taken together, we have all the ingredients of a higher-order logic, and we can
thus state and prove properties of our programs in the same language that we
program in. For example, the property that addition is commutative may be stated
as a function
\begin{verbatim}
  plus-comm : ∀ n m → n + m ≡ m + n
\end{verbatim}
and it is not hard to give a term of this type which serves as a proof.
(\cod{≡} is a specific notion of equality of natural numbers.)


\subsection{Termination Checking}

If we want to view our types as propositions and our programs as proofs, we had
better make sure that our programming language is consistent when viewed as a
logic. This means that the false proposition $⊥$ must not be provable. It is
represented by the data type with no constructors (and thus no canonical
inhabitants):
\begin{verbatim}
  data ⊥ : Set where
\end{verbatim}

If \cod{⊥} is to be uninhabited, this means that there must be no term of type
\cod{⊥}. Unfortunately, writing such a term is rather easy in the language we
have presented so far:
\begin{verbatim}
  bad : ⊥
  bad = bad
\end{verbatim}
\cod{bad} trivially passes the type checker if we allow recursive functions,
which are essential if we are to work with recursive data types like natural
numbers and lists. The problem with \cod{bad} is that it does not terminate: it
is the trivial infinite loop that promises an inhabitant of \cod{⊥} which does
not exist, then never delivers it. The solution is conceptually straightforward:
We demand that all programs terminate, thus ensuring that any term \cod{t : ⊥}
evaluates to a constructor of \cod{⊥} -- which is impossible.

Unfortunately, that is easier said than done. As the halting problem is
undecidable, there can be no computable procedure that accepts exactly the
terminating programs. We must therefore make do with heuristics. In the case of
dependently typed languages, these take the form of termination checkers, which
are traditionally based on the principle of structural recursion. Consider the
addition function on Peano natural numbers:
\begin{verbatim}
  data ℕ : Set where
    zero :     ℕ
    suc  : ℕ → ℕ

  plus : ℕ → ℕ → ℕ
  plus zero    m = m
  plus (suc n) m = suc (plus n m)
\end{verbatim}
In the second equation, \cod{plus} is applied recursively to the argument
\cod{n}. \cod{n} is a subterm of \cod{plus}'s original argument, \cod{suc~n}.
Since we \enquote*{peel off} one constructor for each recursive call, we say
that \cod{plus} is structurally recursive. And since inhabitants of inductive
types like \cod{ℕ} can only consist of finitely many constructors, any
structurally recursive function must eventually terminate. State of the art
termination checkers add a few bells and whistles (e.g. support for mutually
recursive functions), but are still based on structural recursion.


\subsection{Sized Types}

Many interesting functions are naturally structurally recursive, and so are well
served by traditional termination checking. But the traditional approaches are
syntactic in nature, as they look for terms that are syntactically subterms of a
function's arguments. This does not work well for higher-order functions, as
demonstrated by the mapping function on Rose trees:
\begin{verbatim}
  data Tree (A : Set) : Set where
    leaf : A             → Tree A
    node : List (Tree A) → Tree A

  mapTree : (A → B) → Tree A → Tree B
  mapTree f (leaf x)  = leaf (f x)
  mapTree f (node xs) = node (map (mapTree f) xs)
\end{verbatim}
This definition is perfectly natural, but in the second equation of
\cod{mapTree}, we have a recursive call with no subterms in sight! The subterms
which \cod{mapTree} is applied to are the elements of the list \cod{xs}, but
this is not syntactically obvious. We can make the definition palatable to a
syntactic termination checker by inlining \cod{map}, and some termination
checkers even do this for us. But clearly, this is a stopgap measure, and it is
easy to imagine examples where such inlining leads to unreadable and
unmaintainable code, or a very complex termination checker.

In fact, such complexity is another reason to look for better approaches to
termination checking. To accommodate more complex recursion patterns,
termination checkers have grown more sophisticated, but this has lead to bugs in
both Agda's and Coq's termination checkers \cite{coqbug2013, agdabug2013}. Such
bugs are critical: When we manage to get a nonterminating computation past the
checker, a proof of $⊥$ usually follows.

Sized types provide a solution to both problems. To use them, we annotate our
data types with a size, which is an upper bound on the height of their values
(when we consider values of inductive types as trees whose nodes are
constructors). For Rose trees:
\begin{verbatim}
  data TreeS (A : Set) : Size → Set where
    leaf : ∀ s → A                → TreeS A s
    node : ∀ s → List (TreeS A s) → TreeS A (↑ s)
\end{verbatim}
Our trees now have a size index. A leaf has height one, so any size is an upper
bound of the tree's height. For a node, if we have a list of trees of size
\cod{s}, then the resulting tree has size \cod{↑~s} (i.e. \cod{s~+~1}).

Without further ado, we define the mapping function for sized trees:
\begin{verbatim}
  mapTreeS : ∀ {A B} s → (A → B) → TreeS A s → TreeS B s
  mapTreeS .s     f (leaf s x)  = leaf s x
  mapTreeS .(↑ s) f (node s xs) = node s (map (mapTreeS s f) xs)
\end{verbatim}
The first patterns in each equation on the left-hand side are \enquote*{dotted}
because they are forced by matching on the \cod{TreeS} constructors. In
particular, in the second equation, if we have a \cod{node~s~xs}, then the size
argument to \cod{mapTreeS} must have been \cod{↑~s}. The termination checker
now simply checks whether all recursive calls are on sizes smaller than the
function's argument size. Since \cod{s~<~↑~s}, the definition is accepted. In
practice, we would make all size arguments implicit and Agda's size inference
engine would be able to figure them out for us, simplifying the definition even
further.

Sized types address both of our problems with syntactic termination checkers:
They work better with higher-order functions, as demonstrated, and termination
checking is mostly subsumed by type checking, simplifying the implementation.
(Size inference is nontrivial, but bugs there do not compromise the language's
consistency.) They also work better with coinductive types, which describe
potentially infinite data structures like infinite lists.


\subsection{Related Work}

Several type systems with sized types have been investigated before, and various
models of them have been constructed in order to establish desirable properties
of the respective calculi. Some representative works include:
\begin{itemize}
  \item Barthe et al. \cite{barthe2004} investigate a simply typed lambda
    calculus with sized types by constructing a model in terms of saturated sets.
    Amadio and Coupet-Grimal \cite{amadio1998} investigate a similar system using
    Partial Equivalence Relations.
  \item Sacchini \cite{sacchiniphd, sacchini2013} considers a dependent type
    theory enriched with a sized type of streams (but not arbitrary sized types)
    and bases his model on Altenkirch's Λ-sets \cite{altenkirch1993}.
  \item Abel and Pientka \cite{abel2016} investigate System $\mathrm{F}_\mathrm{ω}$ with
    sized types, using a model based on Girard's (set theoretic) reducibility
    candidates \cite{girard1989}.
\end{itemize}

In contrast to these papers, our approach is category-theoretical rather than
set-theoretical. This means that our construction will be (at least mostly)
constructive. It should also be easier to integrate into future developments of
categorical models for type theories with sized types.

\section{Goals and Challenges}
\label{sec:goal}

The goal of our thesis is to construct a constructive, category-theoretical
model of a simply-typed lambda calculus extended with sized types. The model
should demonstrate two crucial properties of the calculus: consistency, meaning
that we cannot construct a closed inhabitant of the empty type; and size
irrelevance, meaning that the result of a computation involving sizes does not
depend on these sizes. In practice, size irrelevance allows us to erase sizes
during compilation.

The construction of such a model presents several technical and conceptual
challenges:
\begin{itemize}
\item We must define a lambda calculus whose type system captures all relevant
  properties of Agda's sized types, to give us some confidence that a model of
  this calculus would generalise to Agda's type system. In particular, the
  calculus must include bounded size quantification, size subtyping, and at least
  one inductive and one coinductive sized type with associated fixed-point
  combinators.
\item We must find an appropriate model of sizes. These are traditionally
  thought of as ordinals, but encoding ordinals in a constructive type theory
  is nontrivial.
\item Agda features a size ∞ which denotes fully defined types. For example, if
  $ℕ~i$ is the type of natural numbers with at most $i$ constructors, then $ℕ~∞$
  is isomorphic to $ℕ$. However, it is unclear whether we can construct an
  ordinal that is \enquote*{large enough} to serve as a model of ∞.

  Even more dubious is a rule in Agda's type system which states that $∞ < ∞$.
  In our model, where ∞ is an ordinal, this would mean that the less-than
  relation on ordinals is reflexive, which is obviously false. Thus, we will
  either have to drop this rule or find a different model of ∞.
\item Sized types can be co-, contra- or mixed-variant in the size. For example,
  the type $ℕ~i$ represents natural numbers with at most $i$ constructors, i.e.
  natural numbers less than $i$. For $i < j$, $ℕ~i$ is then a subtype of $ℕ~j$,
  so $ℕ$ is covariant. On the other hand, the type of sized streams, $𝕊~i$,
  represents streams with \emph{at least} $i$ elements, so $𝕊~i$ is a
  \emph{supertype} of $𝕊~j$ for $i < j$; $𝕊$ is thus contravariant. And as
  usual, functions between sized types are contravariant in the domain and
  covariant in the codomain, so they are overall mixed-variant. Our model must
  therefore be able to accommodate types with different variances.
\end{itemize}


\section{Limitations}

Our base calculus is the simply-typed lambda calculus, which is obviously much
simpler than Agda. It is therefore possible that our model will not readily
generalise to more complex type theories, in particular dependent types. Thus,
even if we manage to construct a model which demonstrates the consistency of our
calculus, this does not mean that Agda-with-sized-types is consistent, and the
same caveat applies to size irrelevance. However, the known examples of
inconsistency involving sized types in Agda use dependent types only in very
limited ways. We therefore suspect that the problems with Agda's sized types do
not result from the combination with dependent types, but will already become
apparent in our simply-typed setting.

Our formulation of sized types may also have to deviate from Agda's to make the
model construction feasible, but we will strive to minimise the difference.


\section{Approach}

\subsection{Mathematical Prerequisites}

Prior to this project, we have already formalised some basics of category theory
in Agda \cite{cats}, including cartesian closed categories and presheaf
categories, which will form the basis of our model. We will extend this
formalisation as need, for example with exponentials of presheaves.

\subsection{Object Language}

Before we can construct a model, we must first say what it is that we model.
Thus, we have defined as our object language a simply-typed lambda calculus
extended with sized types. More specifically, these extensions are:
\begin{itemize}
\item Sizes, including size variables, a size successor and ∞ (the
  \enquote*{infinite} size).
\item Bounded quantification over sizes, i.e. quantifiers $∀x<i$ where $x$ is
  a size variable and $i$ is a size.
\item A type $ℕ~i$ of sized natural numbers (for any size $i$) and a type $𝕊~i$
  of sized streams, along with appropriate introduction and elimination
  principles.
\item Subtyping for $ℕ~i$ and $𝕊~i$ as outlined in Sec. \ref{sec:goal}.
\end{itemize}

\subsection{Ordinals}

To model sizes, we need a constructive representation of ordinals. So far, we
have formalised Taylor's plump ordinals \cite{taylor1996} as presented by
Shulman \cite{shulman2014}. These have many of the basic properties that we
would expect ordinals to have. However, we have also discovered a lemma about
plump ordinals that holds only classically, and there may well be more. We may
thus have to switch to a different representation of ordinals or make the model
classical after all, depending on which properties we need our ordinals to have.

\subsection{Model of Types}

Our current modelling approach is based on the idea that the sized type $ℕ~i$
should be modelled by the set $\{n ∈ ℕ \;|\; n < ⟦i⟧ \}$, where $⟦i⟧$ is the
ordinal corresponding to the size $i$. This suggests that in general, a sized
type $T : \mathrm{Size} → \mathrm{Type}$ should correspond to a functor $\Ords →
\Sets$. $\Ords$ is the preorder category whose objects are ordinals and whose
morphisms between ordinals $s, s′$ are proofs that $s < s′$. $\Sets$ is the
usual category of sets and functions. Since $⟦T⟧$ is a functor, we have
a morphism from $⟦T⟧~s$ to $⟦T⟧~s′$ for ordinals $s < s'$, which corresponds to
size subtyping.

However, as mentioned in Sec. \ref{sec:goal}, the object language includes not
only covariant sized types like $ℕ$, but also contra- and mixed-variant sized
types. Thus, instead of representing a type as a functor $\Ords → \Sets$, we
consider functors $\op{\Ords} × \Ords → \Sets$. The first argument is then a
\enquote*{contravariant size}, the second argument a \enquote*{covariant size}.
A covariant sized type corresponds to a functor which ignores its first argument;
a contravariant sized type ignores the second argument; and a mixed-variant type uses
both arguments.

This model of types can, for the most part, be extended to terms and judgements
in the usual way. However, there are still many open questions surrounding the
order on sizes/ordinals, the size successor and the size $∞$, as mentioned in
Sec. \ref{sec:goal}.

\subsection{Application to Agda}

Part of the motivation for this project is to investigate consistency issues
with Agda's current implementation of sized types. We hope that our work will
suggest ways to fix these. If time permits, we may even be able to implement
these fixes as part of the thesis, though this is unlikely.


\section{Risk Analysis and Ethical Considerations}

This project poses no substantial risks.


\section{Schedule}

The following plan assumes that the project will take 20 weeks to complete.
Four additional weeks are reserved for holidays (2 weeks), a spring school
(1 week) and finalising the thesis report (1 week). All dates are preliminary.

\begin{tabular}{ll}
  14.02. (week 7) & Project start \\
  01.03. & Writing seminar 1 \\
  11.--17.03. & Holidays \\
  01.--06.04. & School and Workshop on Univalent Mathematics, Birmingham \\
  06.05. & Halftime report \\
  07.05. & Industry collaboration and career advancement seminar \\
  08.05. & Writing seminar 2 \\
  27.05.--02.06. & Holidays \\
  22.06. & Thesis presentation \\
  29.06. (week 31) & Final report
\end{tabular}


\bibliographystyle{plain}

\bibliography{planning}

\end{document}